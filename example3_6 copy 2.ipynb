{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Trading of BABA US Equity and 9988 HK Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from xbbg import blp\n",
    "from datetime import datetime\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "\n",
    "def run_pairs_strategy(ticker1, ticker2, start_date, end_date):\n",
    "    # Clean up ticker names for column names\n",
    "    def sanitize_ticker(ticker):\n",
    "        return ticker.replace(' ', '_').replace('.', '').replace('&', 'and').replace('/', '_')\n",
    "\n",
    "    ticker1_clean = sanitize_ticker(ticker1)\n",
    "    ticker2_clean = sanitize_ticker(ticker2)\n",
    "\n",
    "    # Retrieve data\n",
    "    df1 = blp.bdh(ticker1, 'PX_LAST', start_date, end_date, FX='USD')\n",
    "    df2 = blp.bdh(ticker2, 'PX_LAST', start_date, end_date, FX='USD')\n",
    "\n",
    "    # Data processing\n",
    "    df1.reset_index(inplace=True)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df1.columns = ['Date', 'Adj Close']\n",
    "    df2.columns = ['Date', 'Adj Close']\n",
    "\n",
    "    df = pd.merge(df1, df2, on='Date', suffixes=('_' + ticker1_clean, '_' + ticker2_clean))\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    coint_t, pvalue, crit_value = coint(df['Adj Close_' + ticker1_clean], df['Adj Close_' + ticker2_clean])\n",
    "    print( coint_t, pvalue, crit_value)\n",
    "\n",
    "    trainset = np.arange(0, 350)\n",
    "    testset = np.arange(trainset.shape[0], df.shape[0])\n",
    "\n",
    "    # Build OLS model\n",
    "    model = sm.OLS(df['Adj Close_' + ticker1_clean].iloc[trainset],\n",
    "                   df['Adj Close_' + ticker2_clean].iloc[trainset])\n",
    "    results = model.fit()\n",
    "    hedgeRatio = results.params\n",
    "\n",
    "    # Compute spread\n",
    "    spread = df['Adj Close_' + ticker1_clean] - hedgeRatio[0] * df['Adj Close_' + ticker2_clean]\n",
    "    spreadMean = np.mean(spread.iloc[trainset])\n",
    "    spreadStd = np.std(spread.iloc[trainset])\n",
    "\n",
    "    df['zscore'] = (spread - spreadMean) / spreadStd\n",
    "\n",
    "    # Positions\n",
    "    df['positions_' + ticker1_clean + '_Long'] = 0\n",
    "    df['positions_' + ticker2_clean + '_Long'] = 0\n",
    "    df['positions_' + ticker1_clean + '_Short'] = 0\n",
    "    df['positions_' + ticker2_clean + '_Short'] = 0\n",
    "\n",
    "    df.loc[df.zscore >= 3, ('positions_' + ticker1_clean + '_Short', 'positions_' + ticker2_clean + '_Short')] = [-1, 1]  # Short spread\n",
    "    df.loc[df.zscore <= -3, ('positions_' + ticker1_clean + '_Long', 'positions_' + ticker2_clean + '_Long')] = [1, -1]  # Buy spread\n",
    "    df.loc[df.zscore <= 2.5, ('positions_' + ticker1_clean + '_Short', 'positions_' + ticker2_clean + '_Short')] = 0  # Exit short spread\n",
    "    df.loc[df.zscore >= -2.5, ('positions_' + ticker1_clean + '_Long', 'positions_' + ticker2_clean + '_Long')] = 0  # Exit long spread\n",
    "\n",
    "    df.fillna(method='ffill', inplace=True)  # Carry forward existing positions unless there is an exit signal\n",
    "\n",
    "    # Calculate positions and PnL\n",
    "    positions_Long = df[['positions_' + ticker1_clean + '_Long', 'positions_' + ticker2_clean + '_Long']]\n",
    "    positions_Short = df[['positions_' + ticker1_clean + '_Short', 'positions_' + ticker2_clean + '_Short']]\n",
    "    positions = positions_Long.values + positions_Short.values\n",
    "    positions = pd.DataFrame(positions, columns=[ticker1_clean, ticker2_clean], index=df.index)\n",
    "    dailyret = df[['Adj Close_' + ticker1_clean, 'Adj Close_' + ticker2_clean]].pct_change()\n",
    "\n",
    "    pnl = (positions.shift() * dailyret.values).sum(axis=1)\n",
    "    pnl = pnl - abs(positions - positions.shift()).sum(axis=1) * 0.002 # pnl - cost of transactions at 0.005\n",
    "    sharpeTrainset = np.sqrt(252) * np.mean(pnl[trainset[1:]]) / np.std(pnl[trainset[1:]])\n",
    "    sharpeTestset = np.sqrt(252) * np.mean(pnl[testset]) / np.std(pnl[testset])\n",
    "\n",
    "    # Plot spread and cumulative PnL\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(211)\n",
    "    plt.title(f\"Spread for {ticker1} and {ticker2}\")\n",
    "    plt.plot(spread.iloc[trainset], label='Train Spread')\n",
    "    plt.plot(spread.iloc[testset], label='Test Spread')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.title(f\"Cumulative PnL for {ticker1} and {ticker2}\")\n",
    "    plt.plot(np.cumsum(pnl[testset]), label='Test PnL')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save positions\n",
    "    positions.to_pickle(f'positions_{ticker1_clean}_{ticker2_clean}.pkl')\n",
    "\n",
    "    # Return outputs\n",
    "    return {\n",
    "        'sharpeTrainset': sharpeTrainset,\n",
    "        'sharpeTestset': sharpeTestset,\n",
    "        'positions': positions,\n",
    "        'pnl': pnl,\n",
    "        'df': df\n",
    "    }\n",
    "\n",
    "# Define your list of pairs\n",
    "pairs_list = [\n",
    "    # Hong Kong/China\n",
    "    ('SILV Comdty', 'SIL US Equity')  # Alibaba Group Holding Ltd.\n",
    "    #('TCEHY US Equity', '700 HK Equity'),  # Tencent Holdings Ltd.\n",
    "    #('MNSO US Equity', '9896 HK Equity'),  # MINISO Group Holding Ltd.\n",
    "    #('JD US Equity', '9618 HK Equity')    # JD.com Inc.\n",
    "    #('PNGAY US Equity', '2318 HK Equity'), # Ping An Insurance (Group) Co. of China Ltd.\n",
    "    #('BIDU US Equity', '9888 HK Equity'),  # Baidu Inc.\n",
    "    #('NTES US Equity', '9999 HK Equity'),  # NetEase Inc.\n",
    "    #('XIACY US Equity', '1810 HK Equity'), # Xiaomi Corp.\n",
    "    #('MPNGY US Equity', '3690 HK Equity'), # Meituan Dianping\n",
    "    #('LI US Equity', '2015 HK Equity'),    # Li Auto Inc.\n",
    "    #('XPEV US Equity', '9868 HK Equity'),  # XPeng Inc.\n",
    "    #('TCOM US Equity', '9961 HK Equity'),  # Trip.com Group Ltd.\n",
    "    #('YUMC US Equity', '9987 HK Equity'),  # Yum China Holdings Inc.\n",
    "]\n",
    "\n",
    "start_date = '2020-01-01'  # Adjust the start date as needed\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')  # Today's date in 'YYYY-MM-DD' format\n",
    "\n",
    "# Loop over each pair and run the strategy\n",
    "for ticker1, ticker2 in pairs_list:\n",
    "    print(f\"Processing pair: {ticker1}, {ticker2}\")\n",
    "    results = run_pairs_strategy(ticker1, ticker2, start_date, end_date)\n",
    "    print(f\"Sharpe Ratio (Train): {results['sharpeTrainset']}\")\n",
    "    print(f\"Sharpe Ratio (Test): {results['sharpeTestset']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PnLs into a DataFrame\n",
    "pnl_df = pd.concat(pnl_list, axis=1)\n",
    "pnl_df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate total PnL by averaging PnLs (equal weights)\n",
    "total_pnl = pnl_df.mean(axis=1)\n",
    "\n",
    "# Compute cumulative PnL\n",
    "cumulative_pnl = total_pnl.cumsum()\n",
    "\n",
    "# Compute cumulative returns\n",
    "cumulative_returns = (1 + total_pnl).cumprod()\n",
    "\n",
    "# Number of days\n",
    "N = len(total_pnl)\n",
    "\n",
    "# Compute annualized return\n",
    "annualized_return = (cumulative_returns.iloc[-1]) ** (252 / N) - 1\n",
    "\n",
    "# Compute annualized volatility\n",
    "annualized_volatility = total_pnl.std() * np.sqrt(252)\n",
    "\n",
    "# Compute maximum drawdown\n",
    "running_max = cumulative_returns.cummax()\n",
    "drawdown = cumulative_returns / running_max - 1\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "# Compute Sharpe Ratio for the combined portfolio\n",
    "sharpe_total = np.sqrt(252) * total_pnl.mean() / total_pnl.std()\n",
    "print(f\"Combined Portfolio Sharpe Ratio: {sharpe_total}\")\n",
    "\n",
    "# Print the annualized performance metrics\n",
    "print(f\"Annualized Return: {annualized_return:.2%}\")\n",
    "print(f\"Annualized Standard Deviation (Volatility): {annualized_volatility:.2%}\")\n",
    "print(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "\n",
    "# Plot cumulative PnL of the combined portfolio\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Cumulative PnL of Combined Portfolio\")\n",
    "plt.plot(cumulative_pnl)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative PnL\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
